{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "## Your name here\n",
    "\n",
    "Instructions: \n",
    "\n",
    "1. Replace \"yourname\" in the filename of this notebook, and \"your name here\" in this header, with your name. \n",
    "2. Complete all questions/problems. **Make sure to run all cells so that your output is visible**. \n",
    "3. Run \"restart & run all\" from the Kernel menu, to make sure that it's all running in order. \n",
    "4. Email me your notebook (.ipynb file) to jonathan.reeve@columbia.edu. Please don't email me archives (`.zip` or `.tar.gz`) or extra texts. Write the word \"lobster\" somewhere in your email, so that I know you read these instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install SpaCy and the SpaCy language model called `en_core_web_lg`. \n",
    "\n",
    "It is important that you get this particular language model, as the others don't have the features we'll need. \n",
    "\n",
    "You're welcome to work together in groups for this one (probably in groups where you all run the same operating system). \n",
    "\n",
    "There are installation instructions [here on the SpaCy website](https://spacy.io/usage/) that list a number of command-line commands to run. To run command-line commands: \n",
    "\n",
    " - **Linux**: open a terminal. \n",
    " - **MacOS**: open the Terminal app. (Hint: you can open Spotlight, the magnifying glass icon in the upper right, and type \"terminal\")\n",
    " - **Windows**: open Powershell. (Open the Start menu, then type \"powershell.\") Alternatively, download Git BASH, which is included in GitHub Desktop. \n",
    "\n",
    "Whenever you see command-line commands, they're usually prefixed with `$` or `#`. A `$` means to run the command as a regular user, and a `#` means to prefix your command with `sudo`. You'll generally only see `$`, and you're already running as a regular user, so all you'll need to do is to type in the command that follows the `$`, i.e. not including the `$`. So if the command is shown in the SpaCy docs as `$ conda install -c conda-forge spacy`, open a terminal and type `conda install -c conda-forge spacy`, exactly as written. \n",
    "\n",
    "When following the SpaCy instructions, you'll want to choose `conda` as your package manager (because you've installed Anaconda), and 'python3' as your Python version, since we're using Python 3 in this course. Don't select `virtualenv` unless you really know what you're doing. \n",
    "\n",
    "To show that you've successfully installed this stack, please run the two cells below, to show that it's not giving you errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the corpus that you'll use for your final project, and put it into a dictionary with labels as the keys. \n",
    "\n",
    "Consult [the final project instructions](https://github.com/JonathanReeve/course-computational-literary-analysis/blob/master/Resources/final-project-instructions.md#choosing-a-corpus) on choosing a corpus. Feel free to use [corpus-db.org](http://corpus-db.org) to assemble your corpus. If you need any help in using it, please ask in the chatroom! You can use it to get, say, 30 detective novels relatively easily, or 30 novels that feature young women, or 30 novels set in Paris. You can also get all the works by a certain author this way. But be careful to know exactly what texts you're getting. Project Gutenberg includes texts in a number of languages, so select your texts carefully. \n",
    "\n",
    "If you have a directory of text files, you can easily load all the files in your directory with `glob`, using something like:\n",
    "\n",
    "```python\n",
    "{filename: open(filename).read() for filename in glob.glob('*.txt')}\n",
    "```\n",
    "\n",
    "Stick with English texts, please. NLP in other languages is possible, but requires a different set of tokenizers and other tools that we haven't used yet in this course. It's also good idea to work with texts that are originally written in English, since translations have the problem of introducing translator's word choices to the set of word choices that the author has already made.\n",
    "\n",
    "Your corpus should be a collection of texts, stored in one variable. However, it doesn't have to be a collection of *works*. Rather, it can be all the narratives in _The Moonstone_, all of Katherine Mansfield's stories, all of Joyce's stories, or some combination of the above, based on theme or genre. It can also be all the novels of a certain writer, or of five writers. Comparisons make for good corpora. Why not compare, say, all of our Joyce stories to all of our Mansfield stories? You'll probably want to have more than four documents, and less than a thousand, for the analyses that follow. \n",
    "\n",
    "You can also use certain APIs to get texts like book reviews. Use `requests.get` along with a URL you get from the API's documentation. Maybe you're interested in comparing texts and their reviews? \n",
    "\n",
    "Your corpus might change a little by the time you finish your final project, and that's OK, but try not to change it completely, if you can. \n",
    "\n",
    "Make sure to clean your corpus of paratext: tables of contents, Project Gutenberg copyright licenses, etc, since these will throw off text statistics. \n",
    "\n",
    "Print out just enough of your corpus to show that it's well-structured, i.e., the first 100 characters of each text. Don't do this if you have 1000 texts, though—just print out a preview of it. \n",
    "\n",
    "**Please don't print out the entire contents of your corpus, or include any of your text files in your homework.**\n",
    "\n",
    "Finally, write a paragraph in Markdown where you describe your sources, and how you organized your corpus. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the length, in words, of each text in your corpus. Make a chart that shows how they compare. \n",
    "\n",
    "Then, in a markdown cell, write about how these different lengths may affect your analysis, and how you might counteract the effects of different text lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute the type-token ratio for each text in your corpus. Make a chart that shows how they compare. \n",
    "\n",
    "Don't forget to truncate each text to a reasonable value (usually the length of your shortest text).\n",
    "\n",
    "Then, in a markdown cell, write about what you notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Show some frequent n-grams for each text in your corpus.\n",
    "\n",
    "Don't print out too much—just enough to get the idea. \n",
    "\n",
    "Then, in a markdown cell, write about what you notice about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Choose a word, or an n-gram, which you think may be significant for your corpus. Make a chart that shows the proportions of that term across all the texts in your corpus. \n",
    "\n",
    "Make sure to use proportions, and not counts. Then, in the markdown cell, write about what you notice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Run a comparative stylometric analysis of the texts in your corpus. \n",
    "\n",
    "So, make document-term matrices for your most frequent words, reduce their dimensions to 2 or 3 using PCA, and make a labeled scatter plot and/or dendrogram of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Add the category texts of the Brown Corpus to your stylometric analysis, and create a new visualization which includes these texts.\n",
    "\n",
    "Then, write about how your texts compare with the texts of the Brown Corpus, and what you think that means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Repeat your analysis from #7, only this time, use semantic words rather than syntactic words. \n",
    "\n",
    "In other words, instead of choosing the top 800 most frequent words, or whatever that number is for your texts, choose all the *other* words, which will be the content words. You may want to limit your selection to words that are in all documents, e.g., by setting `min_df` to `1.0` in `TfIdfVectorizer`. \n",
    "\n",
    "You'll want to look through the word frequency lists for your corpus to determine where semantic words start in your ranked list of words (after the thousandth most frequent word, maybe?). \n",
    "\n",
    "Write about what you found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Topic-model your corpus using LDA, and create a chart which shows some topics. \n",
    "\n",
    "Experiment with different parameters until you find the ones that give you the most interpretable results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Make a simple genre categorizer that tries to guess the genre of a text, based on word frequencies derived from the Brown corpus. Test it on all of Mansfield's stories that we've read. \n",
    "\n",
    "Then, write about why you think your categorizer guessed those genres for these stories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
